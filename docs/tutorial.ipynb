{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rechunker Tutorial\n",
    "\n",
    "This tutorial notebook explains how to use rechunker with real datasets. We will also use xarray to make some things easier and prettier, but we note that xarray is not a dependency for rechunker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example\n",
    "\n",
    "### Create Example Data\n",
    "\n",
    "Here we load one of xarray's tutorial datasets and write it to Zarr. This is not actually a big dataset, so rechunker is not really needed here. But it's a convenient example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "xr.set_options(display_style='text')\n",
    "import zarr\n",
    "import dask.array as dsa\n",
    "\n",
    "ds = xr.tutorial.open_dataset(\"air_temperature\")\n",
    "# create initial chunk structure\n",
    "ds = ds.chunk({'time': 100})\n",
    "ds.air.encoding = {} # helps when writing to zarr\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the chunk structure of the data variable using Dask's pretty Array repr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf *.zarr # clean up any existing temporary data\n",
    "ds.to_zarr('air_temperature.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we open up a Zarr Group and Array that we will use as inputs to rechunker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_group = zarr.open('air_temperature.zarr')\n",
    "print(source_group.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_array = source_group['air']\n",
    "source_array.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechunk a single Array\n",
    "\n",
    "The original array has chunks of (100, 25, 53). Let's rechunk it to be contiguous in time, but chunked in space.\n",
    "We specify a small value of `max_mem` in order to force rechunker to create an intermediate dataset. We also have to specify a place to store the final and intermediate data.\n",
    "\n",
    "We use the [rechunk](api.rst#rechunker.rechunk) function, which returns a [Rechunked](api.rst#rechunker.Rechunked) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rechunker import rechunk\n",
    "\n",
    "target_chunks = (2920, 25, 1)\n",
    "max_mem = '1MB'\n",
    "\n",
    "target_store = 'air_rechunked.zarr'\n",
    "temp_store = 'air_rechunked-tmp.zarr'\n",
    "\n",
    "array_plan = rechunk(source_array, target_chunks, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this array has dimensions, we can also specify the chunks using a dictionary syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_chunks_dict = {'time': 2920, 'lat': 25, 'lon': 1}\n",
    "\n",
    "# need to remove the existing stores or it won't work\n",
    "!rm -rf air_rechunked.zarr air_rechunked-tmp.zarr\n",
    "array_plan = rechunk(source_array, target_chunks_dict, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `array_plan` is a `Rechunked` object.\n",
    "It has not actually performed the rechunking yet.\n",
    "To do this, we need to call the `execute` method.\n",
    "This will use Dask to perform the rechunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = array_plan.execute()\n",
    "result.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Dask will use the multi-threaded scheduler.\n",
    "Since rechunking can take a long time, we might want to use a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    array_plan.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we create a distributed cluster, then rechunker will use that when it executes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster, progress\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it is written to disk, we can open the rechunked array however we please. Using Zarr..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_array = zarr.open('air_rechunked.zarr')\n",
    "target_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_array_dask = dsa.from_zarr('air_rechunked.zarr')\n",
    "target_array_dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechunk a Group\n",
    "\n",
    "In the example above, we only rechunked a single array.\n",
    "We can open it with Dask, but not Xarray, because it doesn't contain any coordinates or metadata.\n",
    "\n",
    "Rechunker also supports rechunking entire groups.\n",
    "In this case, `target_chunks` must be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_chunks = {\n",
    "    'air': {'time': 2920, 'lat': 25, 'lon': 1},\n",
    "    'time': None, # don't rechunk this array\n",
    "    'lon': None,\n",
    "    'lat': None,\n",
    "}\n",
    "max_mem = '1MB'\n",
    "\n",
    "target_store = 'group_rechunked.zarr'\n",
    "temp_store = 'group_rechunked-tmp.zarr'\n",
    "\n",
    "# need to remove the existing stores or it won't work\n",
    "!rm -rf group_rechunked.zarr group_rechunked-tmp.zarr\n",
    "array_plan = rechunk(source_group, target_chunks, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_plan.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have written a group, we can open it back up with Xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_zarr('group_rechunked.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often groups have many variables sharing all or a subset of dimensions. In the common case that a given dimension should have equivalent chunks in each variable that contains it, chunks can be provided as a simpler dictionary, mapping dimension names to chunksize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend the dataset with some more variables\n",
    "ds_complex = ds\n",
    "ds_complex['air_slice'] = ds.air.isel(lat=10)\n",
    "ds_complex['air_timeseries'] = ds.air.isel(lat=10, lon=10)\n",
    "ds_complex\n",
    "\n",
    "target_chunks = {'time': 2920, 'lat': 25, 'lon': 1}\n",
    "max_mem = '1MB'\n",
    "\n",
    "target_store = 'group_complex_rechunked.zarr'\n",
    "temp_store = 'group_complex_rechunked-tmp.zarr'\n",
    "\n",
    "# need to remove the existing stores or it won't work\n",
    "!rm -rf group_complex_rechunked.zarr group_complex_rechunked-tmp.zarr\n",
    "\n",
    "# rechunk directly from dataset this time\n",
    "array_plan = rechunk(ds_complex, target_chunks, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_plan.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_zarr('group_complex_rechunked.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all the variables now have the same time chunks. Other dimensions (if they exist) also have consistent chunks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Example\n",
    "\n",
    "In this example we use real data from Pangeo's [Cloud Data Catalog](http://catalog.pangeo.io/).\n",
    "This dataset is stored in Google Cloud Storage.\n",
    "We also use a [Dask Gateway](https://gateway.dask.org/) distributed cluster to scale up our processing.\n",
    "This part of the tutorial won't work for you unless you are in a [Pangeo Cloud](http://pangeo.io/cloud.html) environment or binder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "cluster = GatewayCluster()\n",
    "cluster.scale(20)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "# a zarr group lives here\n",
    "url = 'gs://pangeo-cmems-duacs'\n",
    "gcs = gcsfs.GCSFileSystem(requester_pays=True)\n",
    "source_store = gcs.get_mapper(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Zarr Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = zarr.open_consolidated(source_store, mode='r')\n",
    "source_array = group['sla']\n",
    "source_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_array.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Rechunking Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mem = '1GB'\n",
    "target_chunks = (8901, 72, 72)\n",
    "# you must have write access to this location\n",
    "store_tmp = gcs.get_mapper('pangeo-scratch/rabernat/rechunker_demo/temp.zarr')\n",
    "store_target = gcs.get_mapper('pangeo-scratch/rabernat/rechunker_demo/target.zarr')\n",
    "r = rechunk(source_array, target_chunks, max_mem,\n",
    "                      store_target, temp_store=store_tmp)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = r.execute()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa.from_zarr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
