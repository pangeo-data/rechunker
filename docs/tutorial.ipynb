{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rechunker Tutorial\n",
    "\n",
    "This tutorial notebook explains how to use rechunker with real datasets. We will also use xarray to make some things easier and prettier, but we note that xarray is not a dependency for rechunker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example\n",
    "\n",
    "### Create Example Data\n",
    "\n",
    "Here we load one of xarray's tutorial datasets and write it to Zarr. This is not actually a big dataset, so rechunker is not really needed here. But it's a convenient example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (lat: 25, time: 2920, lon: 53)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n",
       "  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n",
       "  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air      (time, lat, lon) float32 dask.array&lt;chunksize=(100, 25, 53), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    title:        4x daily NMC reanalysis (1948)\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 25, time: 2920, lon: 53)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n",
       "  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n",
       "  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air      (time, lat, lon) float32 dask.array<chunksize=(100, 25, 53), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    title:        4x daily NMC reanalysis (1948)\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "xr.set_options(display_style='text')\n",
    "import zarr\n",
    "import dask.array as dsa\n",
    "\n",
    "ds = xr.tutorial.open_dataset(\"air_temperature\")\n",
    "# create initial chunk structure\n",
    "ds = ds.chunk({'time': 100})\n",
    "ds.air.encoding = {} # helps when writing to zarr\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the chunk structure of the data variable using Dask's pretty Array repr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 14.76 MiB </td>\n",
       "                        <td> 517.58 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2920, 25, 53) </td>\n",
       "                        <td> (100, 25, 53) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 31 Tasks </td>\n",
       "                        <td> 30 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"159\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"27\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"19\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"39\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"42\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"47\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"36\" y2=\"52\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"54\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"59\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"61\" />\n",
       "  <line x1=\"51\" y1=\"41\" x2=\"51\" y2=\"66\" />\n",
       "  <line x1=\"53\" y1=\"43\" x2=\"53\" y2=\"68\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"58\" y2=\"73\" />\n",
       "  <line x1=\"63\" y1=\"53\" x2=\"63\" y2=\"78\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"65\" y2=\"81\" />\n",
       "  <line x1=\"70\" y1=\"60\" x2=\"70\" y2=\"85\" />\n",
       "  <line x1=\"72\" y1=\"62\" x2=\"72\" y2=\"88\" />\n",
       "  <line x1=\"77\" y1=\"67\" x2=\"77\" y2=\"93\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.41261651458249\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"38\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"40\" y2=\"2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"45\" y2=\"7\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"48\" y2=\"9\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"52\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"55\" y2=\"16\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"60\" y2=\"21\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"65\" y2=\"26\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"67\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"72\" y2=\"33\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"74\" y2=\"36\" />\n",
       "  <line x1=\"51\" y1=\"41\" x2=\"79\" y2=\"41\" />\n",
       "  <line x1=\"53\" y1=\"43\" x2=\"82\" y2=\"43\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"86\" y2=\"48\" />\n",
       "  <line x1=\"63\" y1=\"53\" x2=\"91\" y2=\"53\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"94\" y2=\"55\" />\n",
       "  <line x1=\"70\" y1=\"60\" x2=\"98\" y2=\"60\" />\n",
       "  <line x1=\"72\" y1=\"62\" x2=\"101\" y2=\"62\" />\n",
       "  <line x1=\"77\" y1=\"67\" x2=\"106\" y2=\"67\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"109\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"38\" y1=\"0\" x2=\"109\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 38.48973265594604,0.0 109.0779679500637,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"109\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"109\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"109\" y1=\"70\" x2=\"109\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 109.0779679500637,70.58823529411765 109.0779679500637,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"94.833102\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >53</text>\n",
       "  <text x=\"129.077968\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,129.077968,83.294544)\">25</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">2920</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<xarray-air, shape=(2920, 25, 53), dtype=float32, chunksize=(100, 25, 53), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.air.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x16c135070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! rm -rf *.zarr # clean up any existing temporary data\n",
    "ds.to_zarr('air_temperature.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we open up a Zarr Group and Array that we will use as inputs to rechunker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── air (2920, 25, 53) float32\n",
      " ├── lat (25,) float32\n",
      " ├── lon (53,) float32\n",
      " └── time (2920,) float32\n"
     ]
    }
   ],
   "source": [
    "source_group = zarr.open('air_temperature.zarr')\n",
    "print(source_group.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/air</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">float32</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(2920, 25, 53)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(100, 25, 53)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">15476000 (14.8M)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">9005544 (8.6M)</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">1.7</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">30/30</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name               : /air\n",
       "Type               : zarr.core.Array\n",
       "Data type          : float32\n",
       "Shape              : (2920, 25, 53)\n",
       "Chunk shape        : (100, 25, 53)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
       "Store type         : zarr.storage.DirectoryStore\n",
       "No. bytes          : 15476000 (14.8M)\n",
       "No. bytes stored   : 9005544 (8.6M)\n",
       "Storage ratio      : 1.7\n",
       "Chunks initialized : 30/30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_array = source_group['air']\n",
    "source_array.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechunk a single Array\n",
    "\n",
    "The original array has chunks of (100, 25, 53). Let's rechunk it to be contiguous in time, but chunked in space.\n",
    "We specify a small value of `max_mem` in order to force rechunker to create an intermediate dataset. We also have to specify a place to store the final and intermediate data.\n",
    "\n",
    "We use the [rechunk](api.rst#rechunker.rechunk) function, which returns a [Rechunked](api.rst#rechunker.Rechunked) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Rechunked</h2>\n",
       "        <details>\n",
       "          <summary><b>Source</b></summary>\n",
       "          <p><code>&lt;zarr.core.Array (2920, 25, 53) float32&gt;</code></p>\n",
       "        </details>\n",
       "        <details>\n",
       "<summary><b>Intermediate</b></summary>\n",
       "<p><code>&lt;zarr.core.Array (2920, 25, 53) float32&gt;</code></p>\n",
       "</details>\n",
       "\n",
       "        <details>\n",
       "          <summary><b>Target</b></summary>\n",
       "          <p><code>&lt;zarr.core.Array (2920, 25, 53) float32&gt;</code></p>\n",
       "        </details>\n"
      ],
      "text/plain": [
       "<Rechunked>\n",
       "* Source      : <zarr.core.Array '/air' (2920, 25, 53) float32>\n",
       "\n",
       "* Intermediate: <zarr.core.Array (2920, 25, 53) float32>\n",
       "\n",
       "* Target      : <zarr.core.Array (2920, 25, 53) float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rechunker import rechunk\n",
    "\n",
    "target_chunks = (2920, 25, 1)\n",
    "max_mem = '1MB'\n",
    "\n",
    "target_store = 'air_rechunked.zarr'\n",
    "temp_store = 'air_rechunked-tmp.zarr'\n",
    "\n",
    "array_plan = rechunk(source_array, target_chunks, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this array has dimensions, we can also specify the chunks using a dictionary syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Rechunked</h2>\n",
       "        <details>\n",
       "          <summary><b>Source</b></summary>\n",
       "          <p><code>&lt;zarr.core.Array (2920, 25, 53) float32&gt;</code></p>\n",
       "        </details>\n",
       "        <details>\n",
       "<summary><b>Intermediate</b></summary>\n",
       "<p><code>&lt;zarr.core.Array (2920, 25, 53) float32&gt;</code></p>\n",
       "</details>\n",
       "\n",
       "        <details>\n",
       "          <summary><b>Target</b></summary>\n",
       "          <p><code>&lt;zarr.core.Array (2920, 25, 53) float32&gt;</code></p>\n",
       "        </details>\n"
      ],
      "text/plain": [
       "<Rechunked>\n",
       "* Source      : <zarr.core.Array '/air' (2920, 25, 53) float32>\n",
       "\n",
       "* Intermediate: <zarr.core.Array (2920, 25, 53) float32>\n",
       "\n",
       "* Target      : <zarr.core.Array (2920, 25, 53) float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chunks_dict = {'time': 2920, 'lat': 25, 'lon': 1}\n",
    "\n",
    "# need to remove the existing stores or it won't work\n",
    "!rm -rf air_rechunked.zarr air_rechunked-tmp.zarr\n",
    "array_plan = rechunk(source_array, target_chunks_dict, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `array_plan` is a `Rechunked` object.\n",
    "It has not actually performed the rechunking yet.\n",
    "To do this, we need to call the `execute` method.\n",
    "This will use Dask to perform the rechunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_copy_chunk((slice(0, 100, None), slice(0, 25, None), slice(0, 53, None)))_copy_chunk((slice(100, 200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "\n",
      "_copy_chunk((slice(200, 300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(300, 400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(400, 500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(500, 600, None), slice(0, 25, None), slice(0, 53, None)))_copy_chunk((slice(600, 700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(700, 800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "\n",
      "_copy_chunk((slice(800, 900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(900, 1000, None), slice(0, 25, None), slice(0, 53, None)))_copy_chunk((slice(1000, 1100, None), slice(0, 25, None), slice(0, 53, None)))_copy_chunk((slice(1100, 1200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1200, 1300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "\n",
      "\n",
      "_copy_chunk((slice(1300, 1400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1400, 1500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1500, 1600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1600, 1700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1700, 1800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1800, 1900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1900, 2000, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2000, 2100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2100, 2200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2200, 2300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2300, 2400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2400, 2500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2500, 2600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2600, 2700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2700, 2800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2800, 2900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2900, 2920, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(0, 3, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(3, 6, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(6, 9, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(9, 12, None)))\n",
      "\n",
      "\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(12, 15, None)))\n",
      "\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(15, 18, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(18, 21, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(21, 24, None)))\n",
      "\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(24, 27, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(27, 30, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(30, 33, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(33, 36, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(36, 39, None)))\n",
      "\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(39, 42, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(42, 45, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(45, 48, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(48, 51, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(51, 53, None)))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2920, 25, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = array_plan.execute()\n",
    "result.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Dask will use the multi-threaded scheduler.\n",
    "Since rechunking can take a long time, we might want to use a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed |  0.0s_copy_chunk((slice(0, 100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(100, 200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(200, 300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(300, 400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(400, 500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(500, 600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(600, 700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(700, 800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(800, 900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(900, 1000, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1000, 1100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1100, 1200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1200, 1300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "[#########                               ] | 23% Completed |  0.1s_copy_chunk((slice(1300, 1400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1400, 1500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1500, 1600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1600, 1700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1700, 1800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1800, 1900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1900, 2000, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2000, 2100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2100, 2200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2200, 2300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2300, 2400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2400, 2500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "[##################                      ] | 47% Completed |  0.2s_copy_chunk((slice(2500, 2600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2600, 2700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2700, 2800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2800, 2900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2900, 2920, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(0, 3, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(3, 6, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(6, 9, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(9, 12, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(12, 15, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(15, 18, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(18, 21, None)))\n",
      "[#############################           ] | 72% Completed |  0.3s_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(21, 24, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(24, 27, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(27, 30, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(30, 33, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(33, 36, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(36, 39, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(39, 42, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(42, 45, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(45, 48, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(48, 51, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(51, 53, None)))\n",
      "[########################################] | 100% Completed |  0.4s\n"
     ]
    }
   ],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    array_plan.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we create a distributed cluster, then rechunker will use that when it executes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-r3qkrty3', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-bn0so3yv', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-6lqi6o3m', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-6lsvcs2v', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-4xan14dj', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-r_8zlwv3', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-xbr5qiyc', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/juliusbusecke/code/rechunker/docs/dask-worker-space/worker-29nz_tzq', purging\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster, progress\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Rechunked' object has no attribute 'persist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7c/cchjc_ys3z5_33vyp640xycm0000gn/T/ipykernel_23789/3962758384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_plan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Rechunked' object has no attribute 'persist'"
     ]
    }
   ],
   "source": [
    "future = array_plan.persist()\n",
    "progress(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it is written to disk, we can open the rechunked array however we please. Using Zarr..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array (2920, 25, 53) float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_array = zarr.open('air_rechunked.zarr')\n",
    "target_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 14.76 MiB </td>\n",
       "                        <td> 285.16 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2920, 25, 53) </td>\n",
       "                        <td> (2920, 25, 1) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 54 Tasks </td>\n",
       "                        <td> 53 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"159\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.41261651458249\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"38\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"109\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"0\" x2=\"81\" y2=\"70\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"83\" y2=\"70\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"84\" y2=\"70\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"86\" y2=\"70\" />\n",
       "  <line x1=\"16\" y1=\"0\" x2=\"87\" y2=\"70\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"89\" y2=\"70\" />\n",
       "  <line x1=\"20\" y1=\"0\" x2=\"90\" y2=\"70\" />\n",
       "  <line x1=\"21\" y1=\"0\" x2=\"92\" y2=\"70\" />\n",
       "  <line x1=\"23\" y1=\"0\" x2=\"94\" y2=\"70\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"95\" y2=\"70\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"96\" y2=\"70\" />\n",
       "  <line x1=\"27\" y1=\"0\" x2=\"98\" y2=\"70\" />\n",
       "  <line x1=\"29\" y1=\"0\" x2=\"99\" y2=\"70\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"101\" y2=\"70\" />\n",
       "  <line x1=\"32\" y1=\"0\" x2=\"102\" y2=\"70\" />\n",
       "  <line x1=\"33\" y1=\"0\" x2=\"104\" y2=\"70\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"105\" y2=\"70\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"107\" y2=\"70\" />\n",
       "  <line x1=\"38\" y1=\"0\" x2=\"109\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 38.48973265594604,0.0 109.0779679500637,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"109\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"109\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"81\" y1=\"70\" x2=\"81\" y2=\"96\" />\n",
       "  <line x1=\"83\" y1=\"70\" x2=\"83\" y2=\"96\" />\n",
       "  <line x1=\"84\" y1=\"70\" x2=\"84\" y2=\"96\" />\n",
       "  <line x1=\"86\" y1=\"70\" x2=\"86\" y2=\"96\" />\n",
       "  <line x1=\"87\" y1=\"70\" x2=\"87\" y2=\"96\" />\n",
       "  <line x1=\"89\" y1=\"70\" x2=\"89\" y2=\"96\" />\n",
       "  <line x1=\"90\" y1=\"70\" x2=\"90\" y2=\"96\" />\n",
       "  <line x1=\"92\" y1=\"70\" x2=\"92\" y2=\"96\" />\n",
       "  <line x1=\"94\" y1=\"70\" x2=\"94\" y2=\"96\" />\n",
       "  <line x1=\"95\" y1=\"70\" x2=\"95\" y2=\"96\" />\n",
       "  <line x1=\"96\" y1=\"70\" x2=\"96\" y2=\"96\" />\n",
       "  <line x1=\"98\" y1=\"70\" x2=\"98\" y2=\"96\" />\n",
       "  <line x1=\"99\" y1=\"70\" x2=\"99\" y2=\"96\" />\n",
       "  <line x1=\"101\" y1=\"70\" x2=\"101\" y2=\"96\" />\n",
       "  <line x1=\"102\" y1=\"70\" x2=\"102\" y2=\"96\" />\n",
       "  <line x1=\"104\" y1=\"70\" x2=\"104\" y2=\"96\" />\n",
       "  <line x1=\"105\" y1=\"70\" x2=\"105\" y2=\"96\" />\n",
       "  <line x1=\"107\" y1=\"70\" x2=\"107\" y2=\"96\" />\n",
       "  <line x1=\"109\" y1=\"70\" x2=\"109\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 109.0779679500637,70.58823529411765 109.0779679500637,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"94.833102\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >53</text>\n",
       "  <text x=\"129.077968\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,129.077968,83.294544)\">25</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">2920</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(2920, 25, 53), dtype=float32, chunksize=(2920, 25, 1), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_array_dask = dsa.from_zarr('air_rechunked.zarr')\n",
    "target_array_dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechunk a Group\n",
    "\n",
    "In the example above, we only rechunked a single array.\n",
    "We can open it with Dask, but not Xarray, because it doesn't contain any coordinates or metadata.\n",
    "\n",
    "Rechunker also supports rechunking entire groups.\n",
    "In this case, `target_chunks` must be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Rechunked</h2>\n",
       "        <details>\n",
       "          <summary><b>Source</b></summary>\n",
       "          <p><code>&lt;zarr.hierarchy.Group &#x27;/&#x27;&gt;</code></p>\n",
       "        </details>\n",
       "        <details>\n",
       "<summary><b>Intermediate</b></summary>\n",
       "<p><code>&lt;zarr.hierarchy.Group &#x27;/&#x27;&gt;</code></p>\n",
       "</details>\n",
       "\n",
       "        <details>\n",
       "          <summary><b>Target</b></summary>\n",
       "          <p><code>&lt;zarr.hierarchy.Group &#x27;/&#x27;&gt;</code></p>\n",
       "        </details>\n"
      ],
      "text/plain": [
       "<Rechunked>\n",
       "* Source      : <zarr.hierarchy.Group '/'>\n",
       "\n",
       "* Intermediate: <zarr.hierarchy.Group '/'>\n",
       "\n",
       "* Target      : <zarr.hierarchy.Group '/'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chunks = {\n",
    "    'air': {'time': 2920, 'lat': 25, 'lon': 1},\n",
    "    'time': None, # don't rechunk this array\n",
    "    'lon': None,\n",
    "    'lat': None,\n",
    "}\n",
    "max_mem = '1MB'\n",
    "\n",
    "target_store = 'group_rechunked.zarr'\n",
    "temp_store = 'group_rechunked-tmp.zarr'\n",
    "\n",
    "# need to remove the existing stores or it won't work\n",
    "!rm -rf group_rechunked.zarr group_rechunked-tmp.zarr\n",
    "array_plan = rechunk(source_group, target_chunks, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_copy_chunk((slice(1500, 1600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1600, 1700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2100, 2200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(100, 200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2200, 2300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2800, 2900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2900, 2920, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1700, 1800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1000, 1100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2300, 2400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2400, 2500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1800, 1900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1100, 1200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(300, 400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(400, 500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1900, 2000, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(200, 300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1200, 1300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2500, 2600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1300, 1400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2600, 2700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(500, 600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(600, 700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2000, 2100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 53, None),))\n",
      "_copy_chunk((slice(1400, 1500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2700, 2800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(700, 800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(800, 900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 25, None),))\n",
      "_copy_chunk((slice(0, 2920, None),))\n",
      "_copy_chunk((slice(900, 1000, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(0, 3, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(3, 6, None)))\n",
      "\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(42, 45, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(9, 12, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(36, 39, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(33, 36, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(45, 48, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(39, 42, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(30, 33, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(48, 51, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(6, 9, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(51, 53, None)))\n",
      "\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(12, 15, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(15, 18, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(18, 21, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(21, 24, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(24, 27, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(27, 30, None)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zarr.hierarchy.Group '/'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_plan.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have written a group, we can open it back up with Xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/cchjc_ys3z5_33vyp640xycm0000gn/T/ipykernel_23789/4235005900.py:1: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  xr.open_zarr('group_rechunked.zarr')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (time: 2920, lat: 25, lon: 53)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n",
       "  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n",
       "  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air      (time, lat, lon) float32 dask.array&lt;chunksize=(2920, 25, 1), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...\n",
       "    title:        4x daily NMC reanalysis (1948)</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 2920, lat: 25, lon: 53)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n",
       "  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n",
       "  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air      (time, lat, lon) float32 dask.array<chunksize=(2920, 25, 1), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...\n",
       "    title:        4x daily NMC reanalysis (1948)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.open_zarr('group_rechunked.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often groups have many variables sharing all or a subset of dimensions. In the common case that a given dimension should have equivalent chunks in each variable that contains it, chunks can be provided as a simpler dictionary, mapping dimension names to chunksize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Rechunked</h2>\n",
       "        <details>\n",
       "          <summary><b>Source</b></summary>\n",
       "          <pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:         (lat: 25, time: 2920, lon: 53)\n",
       "Coordinates:\n",
       "  * lat             (lat) float32 75.0 72.5 70.0 67.5 ... 22.5 20.0 17.5 15.0\n",
       "  * lon             (lon) float32 200.0 202.5 205.0 207.5 ... 325.0 327.5 330.0\n",
       "  * time            (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air             (time, lat, lon) float32 dask.array&lt;chunksize=(100, 25, 53), meta=np.ndarray&gt;\n",
       "    air_slice       (time, lon) float32 dask.array&lt;chunksize=(100, 53), meta=np.ndarray&gt;\n",
       "    air_timeseries  (time) float32 dask.array&lt;chunksize=(100,), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    title:        4x daily NMC reanalysis (1948)\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>\n",
       "        </details>\n",
       "        <details>\n",
       "<summary><b>Intermediate</b></summary>\n",
       "<p><code>&lt;zarr.hierarchy.Group &#x27;/&#x27;&gt;</code></p>\n",
       "</details>\n",
       "\n",
       "        <details>\n",
       "          <summary><b>Target</b></summary>\n",
       "          <p><code>&lt;zarr.hierarchy.Group &#x27;/&#x27;&gt;</code></p>\n",
       "        </details>\n"
      ],
      "text/plain": [
       "<Rechunked>\n",
       "* Source      : <xarray.Dataset>\n",
       "Dimensions:         (lat: 25, time: 2920, lon: 53)\n",
       "Coordinates:\n",
       "  * lat             (lat) float32 75.0 72.5 70.0 67.5 ... 22.5 20.0 17.5 15.0\n",
       "  * lon             (lon) float32 200.0 202.5 205.0 207.5 ... 325.0 327.5 330.0\n",
       "  * time            (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air             (time, lat, lon) float32 dask.array<chunksize=(100, 25, 53), meta=np.ndarray>\n",
       "    air_slice       (time, lon) float32 dask.array<chunksize=(100, 53), meta=np.ndarray>\n",
       "    air_timeseries  (time) float32 dask.array<chunksize=(100,), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    title:        4x daily NMC reanalysis (1948)\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...\n",
       "\n",
       "* Intermediate: <zarr.hierarchy.Group '/'>\n",
       "\n",
       "* Target      : <zarr.hierarchy.Group '/'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extend the dataset with some more variables\n",
    "ds_complex = ds\n",
    "ds_complex['air_slice'] = ds.air.isel(lat=10)\n",
    "ds_complex['air_timeseries'] = ds.air.isel(lat=10, lon=10)\n",
    "ds_complex\n",
    "\n",
    "target_chunks = {'time': 2920, 'lat': 25, 'lon': 1}\n",
    "max_mem = '1MB'\n",
    "\n",
    "target_store = 'group_complex_rechunked.zarr'\n",
    "temp_store = 'group_complex_rechunked-tmp.zarr'\n",
    "\n",
    "# need to remove the existing stores or it won't work\n",
    "!rm -rf group_complex_rechunked.zarr group_complex_rechunked-tmp.zarr\n",
    "\n",
    "# rechunk directly from dataset this time\n",
    "array_plan = rechunk(ds_complex, target_chunks, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_copy_chunk((slice(1500, 1600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1600, 1700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1700, 1800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1800, 1900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1900, 2000, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(200, 300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2000, 2100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 100, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(100, 200, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1000, 1100, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1100, 1200, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1200, 1300, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1300, 1400, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1400, 1500, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(800, 900, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(900, 1000, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2800, 2900, None),))\n",
      "_copy_chunk((slice(2900, 2920, None),))\n",
      "_copy_chunk((slice(300, 400, None),))\n",
      "_copy_chunk((slice(400, 500, None),))\n",
      "_copy_chunk((slice(500, 600, None),))\n",
      "_copy_chunk((slice(600, 700, None),))\n",
      "_copy_chunk((slice(700, 800, None),))\n",
      "_copy_chunk((slice(2100, 2200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2200, 2300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2600, 2700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(100, 200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2300, 2400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2800, 2900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2900, 2920, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1700, 1800, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(800, 900, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 100, None),))\n",
      "_copy_chunk((slice(2100, 2200, None),))\n",
      "_copy_chunk((slice(1000, 1100, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(100, 200, None),))\n",
      "_copy_chunk((slice(2400, 2500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1000, 1100, None),))\n",
      "_copy_chunk((slice(2400, 2500, None),))\n",
      "_copy_chunk((slice(1400, 1500, None),))\n",
      "_copy_chunk((slice(2700, 2800, None),))\n",
      "_copy_chunk((slice(300, 400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(600, 700, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1100, 1200, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1200, 1300, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(700, 800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2500, 2600, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1300, 1400, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1600, 1700, None),))\n",
      "_copy_chunk((slice(1900, 2000, None),))\n",
      "_copy_chunk((slice(1400, 1500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 53, None),))\n",
      "_copy_chunk((slice(2500, 2600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2700, 2800, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(700, 800, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2300, 2400, None),))\n",
      "_copy_chunk((slice(2500, 2600, None),))\n",
      "_copy_chunk((slice(0, 25, None),))\n",
      "_copy_chunk((slice(2300, 2400, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2400, 2500, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1700, 1800, None),))_copy_chunk((slice(900, 1000, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1600, 1700, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(600, 700, None), slice(0, 53, None)))\n",
      "\n",
      "_copy_chunk((slice(1100, 1200, None),))\n",
      "_copy_chunk((slice(2100, 2200, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2000, 2100, None), slice(0, 53, None)))_copy_chunk((slice(400, 500, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "\n",
      "_copy_chunk((slice(900, 1000, None),))\n",
      "_copy_chunk((slice(1800, 1900, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2200, 2300, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2000, 2100, None),))\n",
      "_copy_chunk((slice(1500, 1600, None),))\n",
      "_copy_chunk((slice(500, 600, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2200, 2300, None),))\n",
      "_copy_chunk((slice(2800, 2900, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2600, 2700, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2900, 2920, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1500, 1600, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2700, 2800, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(500, 600, None), slice(0, 25, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(300, 400, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(1800, 1900, None),))\n",
      "_copy_chunk((slice(400, 500, None), slice(0, 53, None)))_copy_chunk((slice(1900, 2000, None), slice(0, 53, None)))\n",
      "\n",
      "_copy_chunk((slice(800, 900, None),))\n",
      "_copy_chunk((slice(200, 300, None),))\n",
      "_copy_chunk((slice(200, 300, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(2600, 2700, None),))\n",
      "_copy_chunk((slice(1300, 1400, None),))\n",
      "_copy_chunk((slice(1200, 1300, None),))\n",
      "_copy_chunk((slice(0, 2920, None),))\n",
      "_copy_chunk((slice(0, 2920, None),))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 53, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(0, 3, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(3, 6, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(30, 33, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(33, 36, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(36, 39, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(39, 42, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(42, 45, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(45, 48, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(48, 51, None)))_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(51, 53, None)))\n",
      "\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(6, 9, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(9, 12, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(12, 15, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(15, 18, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(18, 21, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(21, 24, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(24, 27, None)))\n",
      "_copy_chunk((slice(0, 2920, None), slice(0, 25, None), slice(27, 30, None)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zarr.hierarchy.Group '/'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_plan.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/cchjc_ys3z5_33vyp640xycm0000gn/T/ipykernel_23789/3867248564.py:1: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  xr.open_zarr('group_complex_rechunked.zarr')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:         (time: 2920, lat: 25, lon: 53)\n",
       "Coordinates:\n",
       "  * lat             (lat) float32 75.0 72.5 70.0 67.5 ... 22.5 20.0 17.5 15.0\n",
       "  * lon             (lon) float32 200.0 202.5 205.0 207.5 ... 325.0 327.5 330.0\n",
       "  * time            (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air             (time, lat, lon) float32 dask.array&lt;chunksize=(2920, 25, 1), meta=np.ndarray&gt;\n",
       "    air_slice       (time, lon) float32 dask.array&lt;chunksize=(2920, 1), meta=np.ndarray&gt;\n",
       "    air_timeseries  (time) float32 dask.array&lt;chunksize=(2920,), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...\n",
       "    title:        4x daily NMC reanalysis (1948)</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (time: 2920, lat: 25, lon: 53)\n",
       "Coordinates:\n",
       "  * lat             (lat) float32 75.0 72.5 70.0 67.5 ... 22.5 20.0 17.5 15.0\n",
       "  * lon             (lon) float32 200.0 202.5 205.0 207.5 ... 325.0 327.5 330.0\n",
       "  * time            (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n",
       "Data variables:\n",
       "    air             (time, lat, lon) float32 dask.array<chunksize=(2920, 25, 1), meta=np.ndarray>\n",
       "    air_slice       (time, lon) float32 dask.array<chunksize=(2920, 1), meta=np.ndarray>\n",
       "    air_timeseries  (time) float32 dask.array<chunksize=(2920,), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:  COARDS\n",
       "    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n",
       "    platform:     Model\n",
       "    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...\n",
       "    title:        4x daily NMC reanalysis (1948)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.open_zarr('group_complex_rechunked.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all the variables now have the same time chunks. Other dimensions (if they exist) also have consistent chunks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Example\n",
    "\n",
    "In this example we use real data from Pangeo's [Cloud Data Catalog](http://catalog.pangeo.io/).\n",
    "This dataset is stored in Google Cloud Storage.\n",
    "We also use a [Dask Gateway](https://gateway.dask.org/) distributed cluster to scale up our processing.\n",
    "This part of the tutorial won't work for you unless you are in a [Pangeo Cloud](http://pangeo.io/cloud.html) environment or binder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask_gateway'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7c/cchjc_ys3z5_33vyp640xycm0000gn/T/ipykernel_22645/578470573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdask_gateway\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGatewayCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGatewayCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask_gateway'"
     ]
    }
   ],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "cluster = GatewayCluster()\n",
    "cluster.scale(20)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "# a zarr group lives here\n",
    "url = 'gs://pangeo-cmems-duacs'\n",
    "gcs = gcsfs.GCSFileSystem(requester_pays=True)\n",
    "source_store = gcs.get_mapper(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Zarr Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = zarr.open_consolidated(source_store, mode='r')\n",
    "source_array = group['sla']\n",
    "source_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_array.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Rechunking Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mem = '1GB'\n",
    "target_chunks = (8901, 72, 72)\n",
    "# you must have write access to this location\n",
    "store_tmp = gcs.get_mapper('pangeo-scratch/rabernat/rechunker_demo/temp.zarr')\n",
    "store_target = gcs.get_mapper('pangeo-scratch/rabernat/rechunker_demo/target.zarr')\n",
    "r = rechunk(source_array, target_chunks, max_mem,\n",
    "                      store_target, temp_store=store_tmp)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = r.execute()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa.from_zarr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
